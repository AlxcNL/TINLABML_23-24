{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "554a3546-a543-40c8-9bfa-adb94a7dae9a",
   "metadata": {},
   "source": [
    "<a href=\"https://it-omscholing.nl/locaties/hogeschool-rotterdam/\">\n",
    "<div>\n",
    "<a><img src='../pics/banner.PNG'/></a>\n",
    "</div>\n",
    "<div>\n",
    "<a href=''><img src='../pics/miw.PNG'/></a>\n",
    "<em>Author: Jeroen Boogaard</em><br>\n",
    "<em>Source: <a href=\"https://www.geeksforgeeks.org/how-to-implement-a-gradient-descent-in-python-to-find-a-local-minimum/\">GeekforGeeks</a></em><br>    \n",
    "</div>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4421b-b9a4-401e-abca-d53c77c3733a",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "479cafb8-2117-44be-a00c-faafac9323bd",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "02106b24-f026-43e2-a8f7-e31368e1ad8f",
   "metadata": {},
   "source": [
    "**Calculating the loss or cost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d857723-5ecd-49f9-91ed-60d8427543d7",
   "metadata": {},
   "source": [
    "def mean_squared_error(y_true, y_predicted):\n",
    "    cost = np.sum((y_true-y_predicted)**2) / len(y_true)\n",
    "    return cost"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad3e466-24c2-456e-8131-4df07c257f54",
   "metadata": {},
   "source": [
    "**Gradient Descent Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97ec9002-8d92-47dd-9177-a455c6009af6",
   "metadata": {},
   "source": [
    "# Here iterations, learning_rate, stopping_threshold\n",
    "# are hyperparameters that can be tuned\n",
    "def gradient_descent(x, y, iterations = 1000, learning_rate = 0.0001,\n",
    "                     stopping_threshold = 1e-6):\n",
    "     \n",
    "    # Initializing weight, bias, learning rate and iterations\n",
    "    current_weight = 0.1\n",
    "    current_bias = 0.01\n",
    "    iterations = iterations\n",
    "    learning_rate = learning_rate\n",
    "    n = float(len(x))\n",
    "     \n",
    "    costs = []\n",
    "    weights = []\n",
    "    previous_cost = None\n",
    "     \n",
    "    # Estimation of optimal parameters\n",
    "    for i in range(iterations):\n",
    "         \n",
    "        # Making predictions\n",
    "        y_predicted = (current_weight * x) + current_bias\n",
    "         \n",
    "        # Calculationg the current cost\n",
    "        current_cost = mean_squared_error(y, y_predicted)\n",
    " \n",
    "        # If the change in cost is less than or equal to\n",
    "        # stopping_threshold we stop the gradient descent\n",
    "        if previous_cost and abs(previous_cost-current_cost)<=stopping_threshold:\n",
    "            break\n",
    "         \n",
    "        previous_cost = current_cost\n",
    " \n",
    "        costs.append(current_cost)\n",
    "        weights.append(current_weight)\n",
    "         \n",
    "        # Calculating the gradients\n",
    "        weight_derivative = -(2/n) * sum(x * (y-y_predicted))\n",
    "        bias_derivative = -(2/n) * sum(y-y_predicted)\n",
    "         \n",
    "        # Updating weights and bias\n",
    "        current_weight = current_weight - (learning_rate * weight_derivative)\n",
    "        current_bias = current_bias - (learning_rate * bias_derivative)\n",
    "                 \n",
    "        # Printing the parameters for each 1000th iteration\n",
    "        print(f\"Iteration {i+1}: Cost {current_cost}, Weight \\\n",
    "        {current_weight}, Bias {current_bias}\")\n",
    "     \n",
    "     \n",
    "    # Visualizing the weights and cost at for all iterations\n",
    "    plt.figure(figsize = (8,6))\n",
    "    plt.plot(weights, costs)\n",
    "    plt.scatter(weights, costs, marker='o', color='red')\n",
    "    plt.title(\"Cost vs Weights\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.xlabel(\"Weight\")\n",
    "    plt.show()\n",
    "     \n",
    "    return current_weight, current_bias"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cb5b78a3-b072-427a-8fa8-b29981bcfd29",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b493cf4b-9ad5-4b92-a27b-700273794337",
   "metadata": {},
   "source": [
    "X = np.array([32.50234527, 53.42680403, 61.53035803, 47.47563963, 59.81320787,\n",
    "       55.14218841, 52.21179669, 39.29956669, 48.10504169, 52.55001444,\n",
    "       45.41973014, 54.35163488, 44.1640495 , 58.16847072, 56.72720806,\n",
    "       48.95588857, 44.68719623, 60.29732685, 45.61864377, 38.81681754])\n",
    "Y = np.array([31.70700585, 68.77759598, 62.5623823 , 71.54663223, 87.23092513,\n",
    "       78.21151827, 79.64197305, 59.17148932, 75.3312423 , 71.30087989,\n",
    "       55.16567715, 82.47884676, 62.00892325, 75.39287043, 81.43619216,\n",
    "       60.72360244, 82.89250373, 97.37989686, 48.84715332, 56.87721319])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cd09ad8f-d300-4a9d-83b9-6ed672bc2276",
   "metadata": {},
   "source": [
    "<h3>Estimating weight and bias using gradient descent</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a27476a8-307a-4b7d-9ddf-df636fecdb5f",
   "metadata": {},
   "source": [
    "estimated_weight, eatimated_bias = gradient_descent(X, Y, iterations=2000)\n",
    "print(f\"Estimated Weight: {estimated_weight}\\nEstimated Bias: {eatimated_bias}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cb527e5f-9d86-4e97-b00a-3f83dc3b1239",
   "metadata": {},
   "source": [
    "**Making predictions using estimated parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0889b6c1-75af-4dd1-826b-47c0320f2905",
   "metadata": {},
   "source": [
    "Y_pred = estimated_weight*X + eatimated_bias"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "837c5caa-82ff-488b-987d-00b17606b060",
   "metadata": {},
   "source": [
    "**Plotting the regression line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b6423b5-f497-412b-8f72-159e344b56ff",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(X, Y, marker='o', color='red')\n",
    "plt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='blue',markerfacecolor='red',\n",
    "         markersize=10,linestyle='dashed')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
